# awesome-deep-cameras

A curated list of resources on learning-based camera design. 

## Introduction

The seminal work by Shree Nayar and Ramesh Raskar introduced the computer vision community to computational cameras. Since then, fruitful research in imaging HDR scenes, light fields, large depth of fields, etc using computational cameras has been done. 
   
In recent years, the incorporation of deep learning in computational camera design boosted a new wave of research in the computer vision community. The notion of optimizing task-specific cameras using neural networks have been coined as "Deep optics", "End-to-end camera design", "Differentiable optics", etc. 
   
This list is compiled to provide an overview of learning-based camera design research works. There are numerous optimizable components in the imaging pipeline, ranging from aperture patterns, the physical shape of lenses, camera ISPs, active illumination, the list goes on. In this list, each camera component is singled out as an subsection, making it easier for readers to navigate the imaging pipeline.

## Table of Contents
- [Apertures]()
- [Lenses]()
- [Sensors]()
- [Camera ISP]()
- [Object-side coding]()
- [Active illumination / structured light]()
- [Camera systems]()